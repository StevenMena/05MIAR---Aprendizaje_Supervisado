{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenMena/05MIAR---Aprendizaje_Supervisado/blob/main/Programa7_HoldOut(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EJ71aZHhDdrk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2ZmJbFLDdrn",
        "outputId": "75936f0d-972e-47ec-bc2f-155f77e6977a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ],
      "source": [
        "# Carga de datos\n",
        "#datos de tipos de plantas utilizados a nive académico\n",
        "#['setosa' 'versicolor' 'virginica']\n",
        "iris = datasets.load_iris()\n",
        "print(iris.target_names)\n",
        "#display(iris)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT6jKSw1Ddro",
        "outputId": "5feeee57-3cfe-4b9e-ee5b-3d5bfc03f6e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabla de datos: 150 instancias y 4 atributos\n",
            "Valores de la clase: {0, 1, 2}\n",
            "[0 1 2] [50 50 50]\n"
          ]
        }
      ],
      "source": [
        "# Mostrar características de la tabla de datos.\n",
        "# Los # de filas que existen iris.data.shape[0] eje x\n",
        "# Los # de columnas que existen iris.data.shape[1] eje y\n",
        "print(\"Tabla de datos: %d instancias y %d atributos\" % (iris.data.shape[0], iris.data.shape[1]))\n",
        "print(\"Valores de la clase:\", set(iris.target))\n",
        "\n",
        "# Cuantificamos el número de instancias que contiene el dataset por clase\n",
        "valores, ocurrencias = np.unique(iris.target, return_counts=True)\n",
        "print(valores, ocurrencias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO_yKE59Ddro"
      },
      "outputs": [],
      "source": [
        "# Test: hold-out split 80-20%. # Partición externa\n",
        "#Por defecto el shuffle es true, que es lo que me permite que la selección sea aleatoria, si es false no es aleatoria y coge los elementos\n",
        "#en orden, random_state es la semilla, esta debe ser siempre el mimso valor\n",
        "#este efecto de aletoriedad siempre será el mismo si la semilla tiene el mismo valor\n",
        "X_training, X_test, y_training, y_test = train_test_split(iris.data, iris.target, test_size=0.2,shuffle=True random_state=42)\n",
        "valores_test, ocur_test = np.unique(y_test, return_counts=True)\n",
        "print('Test: ', 'clases:', valores_test, ' ocurrencias: ', ocur_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bgNeC8qDdrq"
      },
      "outputs": [],
      "source": [
        "# Estandarizar las características de entrenamiento y de test\n",
        "# Utilizar el mismo fit del training en los datos de test\n",
        "standardizer = StandardScaler()\n",
        "X_training = standardizer.fit_transform(X_training)\n",
        "X_test = standardizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDVoG1ptDdrr"
      },
      "outputs": [],
      "source": [
        "# Validación: hold-out split 80-20%. # Partición interna\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, test_size=0.2, random_state=42)\n",
        "valores_train, ocur_train = np.unique(y_train, return_counts=True)\n",
        "print('Entrenamiento: ', ' clases:', valores_train, '  ocurrencias:', ocur_train)\n",
        "\n",
        "valores_val, ocur_val = np.unique(y_val, return_counts=True)\n",
        "print('Validation:    ', ' clases:', valores_val, '  ocurrencias:', ocur_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngYXwktxDdrr"
      },
      "outputs": [],
      "source": [
        "# Construcción del objeto que contiene el algoritmo de aprendizaje.\n",
        "# Algoritmo de aprendizaje dummy, se establece siempre el mismo valor de la semilla que se utilizo para \n",
        "# hacer la validación hold-out\n",
        "model = DummyClassifier(strategy='prior', random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTRTtN2VDdrs"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del algoritmo de aprendizaje.\n",
        "#Luego más adelante en otras sesiones se va explicar como funcionan los algoritmos de aprendizaje\n",
        "#los datos del entramiento, las clases que representan esos atributos\n",
        "model = model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfgfmwPODdrs"
      },
      "outputs": [],
      "source": [
        "# Evaluación del algoritmo de aprendizaje con el método \"score\" que devuelve directamente la métrica de 'accuracy'\n",
        "val_accuracy = model.score(X_val, y_val)\n",
        "print(\"Exactitud en validación: \", val_accuracy)\n",
        "\n",
        "test_accuracy = model.score(X_test, y_test)\n",
        "print(\"Exactitud en test: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MS4oHNDdDdr3"
      },
      "outputs": [],
      "source": [
        "# Obtenemos las predicciones sobre conjunto de validación y de test\n",
        "y_pred_val = model.predict(X_val)\n",
        "print('Predicciones de validación ', y_pred_val)\n",
        "print('Etiquetas reales validación', y_val)\n",
        "\n",
        "y_pred_test = model.predict(X_test)\n",
        "print('\\nPredicciones de test ', y_pred_val)\n",
        "print('Etiquetas reales test', y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AjghMRsnjPL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QzoKg5GDdr5"
      },
      "outputs": [],
      "source": [
        "# Aplicamos un ejemplo con un clasificador más complejo que el \"dummyclassifier\"\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Definimos algoritmo\n",
        "clf = ???\n",
        "\n",
        "# Entrenamos modelo\n",
        "clf = ???\n",
        "\n",
        "# Calculamos la accuracy y volvemos a parametrizar para mejorar los resultados \n",
        "val_accuracy = ???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuqMHzNmDdsD"
      },
      "outputs": [],
      "source": [
        "# Calculamos la accuracy en test utilizando el mejor de los modelos anteriores\n",
        "test_accuracy = ???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFh_4fToDdsF"
      },
      "outputs": [],
      "source": [
        "# Guardar modelo\n",
        "import pickle\n",
        "with open('../models/model.pickle', 'wb') as fw:\n",
        "    pickle.dump(model, fw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNC8hoEfDdsF"
      },
      "outputs": [],
      "source": [
        "# Cargar modelo\n",
        "with open('../models/model.pickle', 'rb') as fr:\n",
        "    pickle.load(fr)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}