{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenMena/05MIAR---Aprendizaje_Supervisado/blob/main/Examen_C2_MenaChavez_StevenAlberto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naRZ2DVSqxX3"
      },
      "source": [
        "### EXAMEN - Convocatoria 2 - Programación\n",
        "Utilizar el conjunto de datos \"dataset_exam_C2.csv\" para resolver el ejercicio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DxK0439qxYF"
      },
      "source": [
        "#### 1) Carga de datos (0.5 puntos)\n",
        "Cargar el dataframe \"dataset_exam_C2.csv\" y obtener por separado los datos \"X\" y la variable target \"y\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAs2sFfMqxYc"
      },
      "outputs": [],
      "source": [
        "# Cargar el archivo \"dataset_exam_C2.csv\" utilizando la librería pandas\n",
        "\n",
        "\n",
        "# Convertir la información en formato numpy.array()\n",
        "\n",
        "\n",
        "# Separar los datos \"X\" y la variable target \"y\" (el target corresponde a la última columna)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v-nlzQPqxYk"
      },
      "source": [
        "#### 2) Tratamiento de datos (1 punto)\n",
        "¡IMPORTANTE! Si este ejercicio no se consigue resolver, pasad directamente al siguiente cargando el dataset correspondiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP6kfiycqxYn"
      },
      "outputs": [],
      "source": [
        "# Discretizar los atributos relativos a variables categóricas, es decir, no numéricas. \n",
        "# Se recomienda utilizar la función \"isinstance()\" para saber si la variable es numérica o no.\n",
        "# Se recomienda utilizar la función preprocessing.OrdinalEncoder() + \"fit_transform() para realizar directamente la conversión.\n",
        "# Otras funciones que pueden ayudar para tratar la dimensión de los datos son: \"np.expand_dims()\" y \"np.squeeze()\"\n",
        "\n",
        "\n",
        "# Mostrar por pantalla cómo queda el dataset tras discretizar las variables categóricas\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brpO9yQmqxYp"
      },
      "source": [
        "#### 3) Partición de datos externa (1 punto)\n",
        "¡IMPORTANTE!  En caso de no haber realizado con éxito el ejercicio anterior, cargar primero el \"dataset_backup.npy\" utilizando \"np.load()\". Después, vuelve a separar los datos \"X\" y la variable target \"y\".\n",
        "\n",
        "Realizar una partición externa de tipo hold-out seleccionando un 20% de los datos para test (fijar una semilla en 42)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHEga391qxYr"
      },
      "outputs": [],
      "source": [
        "# Partición hold-out seleccionado un 20% de los datos para test. Fijar semilla en 42.\n",
        "\n",
        "\n",
        "# Mostrar por pantalla las dimensiones de los datos de train y test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhYAerSHqxYt"
      },
      "source": [
        "#### 4) Estandarización de los datos de train y test (1 punto)\n",
        "Utilizar el método StandardScaler()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhNucRtbqxYv"
      },
      "outputs": [],
      "source": [
        "# Estandarización de los datos de entrenamiento\n",
        "\n",
        "\n",
        "# Estandarización de los datos de test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkoLD5u-qxYy"
      },
      "source": [
        "#### 5) Selección de atributos en train y test (1 punto)\n",
        "Aplicar el método de mutual_info_regression utilizando la función \"SelectPercentile\" con percentile=90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi283yYXqxYz"
      },
      "outputs": [],
      "source": [
        "# Selección de los atributos de entrenamiento\n",
        "\n",
        "\n",
        "# Selección de los atributos de test\n",
        "\n",
        "\n",
        "# Mostrar por pantalla las dimensiones de los datos de train y test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjmnccW4qxY0"
      },
      "source": [
        "#### 6) Comparación de modelos de regresión mediante validación cruzada (2.5 puntos)\n",
        "Aplicar una validación cruzada interna de K=5 bolsas para optimizar y comparar la capacidad predictiva de los siguientes modelos: K-vecinos más cercanos (KNN) y Support Vector Machine (SVM). La comparación debe realizarse únicamente en términos de coeficiente de determinación (R2) proporcionando resultados de media +- desviación estándar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZPClQS6qxY1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cma93eNqxY2"
      },
      "source": [
        "#### 7) Evaluación de los modelos sobre el conjunto de test (1 punto)\n",
        "- Definir una función \"plot_bisectriz()\" cuyos inputs sean:\n",
        " * \"y\" --> la variable target,\n",
        " * \"y_pred\" --> las predicciones del modelo, y \n",
        " * \"name\" --> el nombre del algoritmo utilizado.\n",
        " \n",
        "- El output de dicha función será un gráfico basado en la bisectriz para ver las sobreestimaciones y subestimaciones de cada modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2NPe4jxqxY3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRXJWVxVqxY4"
      },
      "source": [
        "#### 8) Evaluación de los modelos sobre el conjunto de test (2 puntos)\n",
        "- Entrenar los modelos anteriores utilizando todos los datos de entrenamiento.\n",
        "- Evaluar su rendimiento sobre el conjunto de test.\n",
        "- Llamar a la función \"plot_bisectriz\" para ver las sobreestimaciones y subestimaciones de cada modelo.\n",
        "- Crear una tabla donde se muestren los resultados de todos los modelos.\n",
        " * Las filas serán: R2, MAE, MAPE, MSE y RMSE\n",
        " * Las columnas serán: KNN y SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9zXLz6OqxY5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}