{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenMena/05MIAR---Aprendizaje_Supervisado/blob/main/Examen_C2_MenaChavez_StevenAlberto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naRZ2DVSqxX3"
      },
      "source": [
        "### EXAMEN - Convocatoria 2 - Programación\n",
        "Utilizar el conjunto de datos \"dataset_exam_C2.csv\" para resolver el ejercicio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DxK0439qxYF"
      },
      "source": [
        "#### 1) Carga de datos (0.5 puntos)\n",
        "Cargar el dataframe \"dataset_exam_C2.csv\" y obtener por separado los datos \"X\" y la variable target \"y\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.feature_selection import SelectPercentile, mutual_info_regression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.svm import SVR"
      ],
      "metadata": {
        "id": "O9YCScwJsW2F"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAs2sFfMqxYc"
      },
      "outputs": [],
      "source": [
        "# Cargar el archivo \"dataset_exam_C2.csv\" utilizando la librería pandas\n",
        "\n",
        "\n",
        "# Convertir la información en formato numpy.array()\n",
        "\n",
        "\n",
        "# Separar los datos \"X\" y la variable target \"y\" (el target corresponde a la última columna)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Para cargar el archivo en formato npy\n",
        "data = np.load('dataset_exam_C2_backup.npy', allow_pickle=True)\n",
        "#display(data)\n",
        "\n",
        "# Separar los datos \"X\" y la variable target \"y\" (el target corresponde a la última columna)\n",
        "\n",
        "X =  data[:,:-1]\n",
        "y = data[:,-1]"
      ],
      "metadata": {
        "id": "jqY2Mgi3rwJn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v-nlzQPqxYk"
      },
      "source": [
        "#### 2) Tratamiento de datos (1 punto)\n",
        "¡IMPORTANTE! Si este ejercicio no se consigue resolver, pasad directamente al siguiente cargando el dataset correspondiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP6kfiycqxYn"
      },
      "outputs": [],
      "source": [
        "# Discretizar los atributos relativos a variables categóricas, es decir, no numéricas. \n",
        "# Se recomienda utilizar la función \"isinstance()\" para saber si la variable es numérica o no.\n",
        "# Se recomienda utilizar la función preprocessing.OrdinalEncoder() + \"fit_transform() para realizar directamente la conversión.\n",
        "# Otras funciones que pueden ayudar para tratar la dimensión de los datos son: \"np.expand_dims()\" y \"np.squeeze()\"\n",
        "\n",
        "\n",
        "# Mostrar por pantalla cómo queda el dataset tras discretizar las variables categóricas\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brpO9yQmqxYp"
      },
      "source": [
        "#### 3) Partición de datos externa (1 punto)\n",
        "¡IMPORTANTE!  En caso de no haber realizado con éxito el ejercicio anterior, cargar primero el \"dataset_backup.npy\" utilizando \"np.load()\". Después, vuelve a separar los datos \"X\" y la variable target \"y\".\n",
        "\n",
        "Realizar una partición externa de tipo hold-out seleccionando un 20% de los datos para test (fijar una semilla en 42)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHEga391qxYr",
        "outputId": "77f0fb87-12ef-4f2e-fdca-cda2f34bbbf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de datos de Entrenamiento:  (1070, 6)\n",
            "Matriz de datos de Test:  (268, 6)\n"
          ]
        }
      ],
      "source": [
        "# Partición hold-out seleccionado un 20% de los datos para test. Fijar semilla en 42.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "# Mostrar por pantalla las dimensiones de los datos de train y test\n",
        "print(\"Matriz de datos de Entrenamiento: \", np.shape(X_train))\n",
        "print(\"Matriz de datos de Test: \", np.shape(X_test))\n",
        "\n",
        "#print(X_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhYAerSHqxYt"
      },
      "source": [
        "#### 4) Estandarización de los datos de train y test (1 punto)\n",
        "Utilizar el método StandardScaler()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zhNucRtbqxYv"
      },
      "outputs": [],
      "source": [
        "standardizer = StandardScaler()\n",
        "\n",
        "# Estandarización de los datos de entrenamiento\n",
        "X_train_std = standardizer.fit_transform(X_train)\n",
        "\n",
        "# Estandarización de los datos de test\n",
        "X_test_std = standardizer.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkoLD5u-qxYy"
      },
      "source": [
        "#### 5) Selección de atributos en train y test (1 punto)\n",
        "Aplicar el método de mutual_info_regression utilizando la función \"SelectPercentile\" con percentile=90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi283yYXqxYz",
        "outputId": "1e991d4d-c29e-408b-8112-0e7e189ea695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nueva Matriz de datos de Entrenamiento:  (1070, 5)\n",
            "Nueva Matriz de datos de Test:  (268, 5)\n"
          ]
        }
      ],
      "source": [
        "selector = SelectPercentile(mutual_info_regression, percentile=90)\n",
        "# Selección de los atributos de entrenamiento\n",
        "X_train_selected = selector.fit_transform(X_train_std, y_train)\n",
        "\n",
        "# Selección de los atributos de test\n",
        "X_test_selected = selector.transform(X_test_std)\n",
        "\n",
        "# Mostrar por pantalla las dimensiones de los datos de train y test\n",
        "print(\"Nueva Matriz de datos de Entrenamiento: \", np.shape(X_train_selected))\n",
        "print(\"Nueva Matriz de datos de Test: \", np.shape(X_test_selected))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjmnccW4qxY0"
      },
      "source": [
        "#### 6) Comparación de modelos de regresión mediante validación cruzada (2.5 puntos)\n",
        "Aplicar una validación cruzada interna de K=5 bolsas para optimizar y comparar la capacidad predictiva de los siguientes modelos: K-vecinos más cercanos (KNN) y Support Vector Machine (SVM). La comparación debe realizarse únicamente en términos de coeficiente de determinación (R2) proporcionando resultados de media +- desviación estándar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZPClQS6qxY1",
        "outputId": "466a1556-109e-4907-99e5-d418090d1909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cross_val_R2_K-Vecinos:   0.8142 +/- 0.0279\n",
            "cross_val_R2_SVM:   -0.0957 +/- 0.0324\n"
          ]
        }
      ],
      "source": [
        "#Definir K-vecinos\n",
        "k = 10\n",
        "reg = KNeighborsRegressor(n_neighbors = k, weights='distance', metric='euclidean')\n",
        "\n",
        "#Definir SVM\n",
        "svm = SVR(C=1, kernel='rbf')\n",
        "\n",
        "r2_cv_results = cross_val_score(reg, X_train_selected, y_train, cv = KFold(n_splits=5, shuffle=True, random_state=42), scoring='r2')\n",
        "print(\"cross_val_R2_K-Vecinos:   %0.4f +/- %0.4f\" % (r2_cv_results.mean(), r2_cv_results.std()))\n",
        "\n",
        "\n",
        "r2_cv_results_svm = cross_val_score(svm, X_train_selected, y_train, cv = KFold(n_splits=5, shuffle=True, random_state=42), scoring='r2')\n",
        "print(\"cross_val_R2_SVM:   %0.4f +/- %0.4f\" % (r2_cv_results_svm.mean(), r2_cv_results_svm.std()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cma93eNqxY2"
      },
      "source": [
        "#### 7) Evaluación de los modelos sobre el conjunto de test (1 punto)\n",
        "- Definir una función \"plot_bisectriz()\" cuyos inputs sean:\n",
        " * \"y\" --> la variable target,\n",
        " * \"y_pred\" --> las predicciones del modelo, y \n",
        " * \"name\" --> el nombre del algoritmo utilizado.\n",
        " \n",
        "- El output de dicha función será un gráfico basado en la bisectriz para ver las sobreestimaciones y subestimaciones de cada modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "E2NPe4jxqxY3"
      },
      "outputs": [],
      "source": [
        "def plot_bisectriz(y, y_pred, name):\n",
        "    fig, ax = plt.subplots(1,1)\n",
        "\n",
        "    # Plot bisectriz\n",
        "    ax[0].scatter(y, y_pred, edgecolors=(0, 0, 0))\n",
        "    ax[0].set_xlabel('y')\n",
        "    ax[0].set_ylabel('y_pred')\n",
        "    ax[0].set_title('Bisector for ' + name)\n",
        "    ax[0].plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
        "    ax[0].grid()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRXJWVxVqxY4"
      },
      "source": [
        "\n",
        "#### 8) Evaluación de los modelos sobre el conjunto de test (2 puntos)\n",
        "- Entrenar los modelos anteriores utilizando todos los datos de entrenamiento.\n",
        "- Evaluar su rendimiento sobre el conjunto de test.\n",
        "- Llamar a la función \"plot_bisectriz\" para ver las sobreestimaciones y subestimaciones de cada modelo.\n",
        "- Crear una tabla donde se muestren los resultados de todos los modelos.\n",
        " * Las filas serán: R2, MAE, MAPE, MSE y RMSE\n",
        " * Las columnas serán: KNN y SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9zXLz6OqxY5",
        "outputId": "94b6aca7-c4bc-4201-acf3-9c4b73f9b8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           R2          MAE        MAPE           MSE          RMSE\n",
            "KNN -0.541267  9961.141767   67.073755  2.392797e+08  15468.667948\n",
            "SVM -0.079167  8631.323549  112.436628  1.675394e+08  12943.700587\n"
          ]
        }
      ],
      "source": [
        "#Entrenamiento del KNN\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "#Entrenamiento del SVM\n",
        "svm.fit(X_train, y_train)\n",
        "def mape(y_true,y_pred): \n",
        "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def rmse(y_true,y_pred): \n",
        "  return sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "  \n",
        "\n",
        "# Evaluación de los modelos en el conjunto de test\n",
        "models = {'KNN': reg, 'SVM': svm}\n",
        "# Métricas de evaluación.\n",
        "metrics = {\n",
        "    'R2': r2_score,\n",
        "    'MAE': mean_absolute_error,\n",
        "    'MAPE': mape,\n",
        "    'MSE': mean_squared_error,\n",
        "    'RMSE': rmse\n",
        "    }\n",
        "results = {}\n",
        "\n",
        "#Predecir sobre los datos de test estandarizados\n",
        "for model_name, model in models.items():\n",
        "    y_pred = model.predict(X_test_std)\n",
        "    result = []\n",
        "    for metric_name, metric in metrics.items():\n",
        "        score = metric(y_test, y_pred)\n",
        "        result.append(score)\n",
        "    results[model_name] = result\n",
        "\n",
        "# Impresión de los resultados\n",
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame.from_dict(results, orient='index', columns=metrics.keys())\n",
        "print(df_results)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}