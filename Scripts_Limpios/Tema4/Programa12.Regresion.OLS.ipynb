{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from pprint import pprint\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_validate, KFold, cross_val_predict, train_test_split, cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos.\n",
    "datos = datasets.load_boston()\n",
    "# datos = datasets.fetch_california_housing()\n",
    "X = datos.data\n",
    "y = datos.target\n",
    "print('Dimensiones de X: ', np.shape(X))\n",
    "# print(y)\n",
    "# pprint(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Métricas de evaluación.\n",
    "metricas = {\n",
    "  'MAE':  'neg_mean_absolute_error',\n",
    "  'RMSE': make_scorer(lambda y, y_pred:\n",
    "                      sqrt(metrics.mean_squared_error(y, y_pred)),\n",
    "                      greater_is_better=False),\n",
    "  'MAPE': make_scorer(lambda y, y_pred:\n",
    "                      np.mean(np.abs((y - y_pred) / y)) * 100,\n",
    "                      greater_is_better=False),\n",
    "  'R2':   'r2',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Partición de datos externa\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(np.shape(X_training))\n",
    "print(np.shape(X_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Extracción de características\n",
    "# 3) Estandarización de los datos de entrenamiento\n",
    "standardizer = preprocessing.StandardScaler()\n",
    "X_stdr = standardizer.fit_transform(X_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Selección de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Construcción del algoritmo de aprendizaje.\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1) Validación cruzada interna\n",
    "\n",
    "# Extraer directamente resultados del error para cada bolsa, en lugar de las predicciones\n",
    "cross_val_results = cross_validate(reg, X_stdr, y_training, \n",
    "                                    cv = KFold(n_splits=5, shuffle=True, random_state=42), scoring=metricas)\n",
    "# print(\"cross_val_R2:   %0.4f +/- %0.4f\" % (-cross_val_results.mean(), cross_val_results.std()))\n",
    "pprint(cross_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2) Entrenamiento con todos los datos para obtener los coeficientes del modelo.\n",
    "model = reg.fit(X_stdr, y_training)\n",
    "\n",
    "# Obtención de los coeficientes del modelo.\n",
    "w = model.coef_\n",
    "print('Model coeficients: \\n', w)\n",
    "\n",
    "# Obtención del término independiente del modelo.\n",
    "w_0 = model.intercept_\n",
    "print('\\nTérmino independiente: ', w_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PREDICCIÓN ---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Extracción de las características de test \n",
    "# 7) Estandarización de las característiacs de test\n",
    "X_test_stdr = standardizer.transform(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Selección de los atributos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Predicción del conjunto de test\n",
    "y_pred_test = model.predict(X_test_stdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Cálculo de las métricas de evaluación.\n",
    "MAE = metrics.mean_absolute_error(y_testing, y_pred_test)\n",
    "MSE = metrics.mean_squared_error(y_testing, y_pred_test, squared=True)\n",
    "RMSE = metrics.mean_squared_error(y_testing, y_pred_test, squared=False)\n",
    "R2 = metrics.r2_score(y_testing, y_pred_test)\n",
    "\n",
    "print('MAE:  %.4f' % MAE)\n",
    "print('MSE: %.4f' % MSE)\n",
    "print('RMSE: %.4f' % RMSE)\n",
    "print('R2:   %.4f' % R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get regression graphics\n",
    "def report_regression_graphics(y_true, y_pred):\n",
    "    fig, ax = plt.subplots(2,1)\n",
    "\n",
    "    # Plot linear fit\n",
    "    ax[0].scatter(y_true, y_pred)\n",
    "    ax[0].set_ylabel('y_pred')\n",
    "    ax[0].set_title('Regression line')\n",
    "    ax[0].grid()\n",
    "    # overlay the regression line\n",
    "    z = np.polyfit(np.float64(y_true), y_pred, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax[0].plot(y_true, p(y_true), color='magenta')\n",
    "\n",
    "    # Plot bisectriz\n",
    "    ax[1].scatter(y_true, y_pred, edgecolors=(0, 0, 0))\n",
    "    ax[1].set_xlabel('y_true')\n",
    "    ax[1].set_ylabel('y_pred')\n",
    "    ax[1].set_title('Bisector')\n",
    "    ax[1].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "    ax[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos los resultados cualitativos del problema de regresión\n",
    "report_regression_graphics(y_testing, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información sobre los algoritmos Ridge, Lasso y Elasticnet\n",
    "# https://towardsdatascience.com/whats-the-difference-between-linear-regression-lasso-ridge-and-elasticnet-8f997c60cf29"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
